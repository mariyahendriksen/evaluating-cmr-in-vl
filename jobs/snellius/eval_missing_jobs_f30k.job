#!/bin/bash
#SBATCH -t 100:00:00
#SBATCH -N 1
#SBATCH --cpus-per-task=10
#SBATCH --mem=100gb
#SBATCH --gpus=1
#SBATCH --partition=gpu
#SBATCH -o ./logs/snellius/eval_missing_jobs_f30k.out

source /home/mhendriksen2/miniconda3/etc/profile.d/conda.sh
conda activate /gpfs/home2/mhendriksen2/projects/eval_39

DATASET=f30k
echo 'Dataset: ' $DATASET

MODEL=altclip
declare -a PERTURBATIONS=(
    "extra_char"
    "probability_based_letter_change"
    )
for PERTURBATION in "${PERTURBATIONS[@]}"
do
   echo MODEL: $MODEL
   python src/evaluation.py \
    --dataset $DATASET \
    --model $MODEL \
    --perturbation "$PERTURBATION" \
    --task t2i
done

MODEL=align
declare -a PERTURBATIONS=(
    "extra_char"
    "probability_based_letter_change"
    )
for PERTURBATION in "${PERTURBATIONS[@]}"
do
   echo MODEL: $MODEL
   python src/evaluation.py \
    --dataset $DATASET \
    --model $MODEL \
    --perturbation "$PERTURBATION" \
    --task t2i
done


MODEL=clip
declare -a PERTURBATIONS=(
    "extra_char"
    "probability_based_letter_change"
    )
for PERTURBATION in "${PERTURBATIONS[@]}"
do
   echo MODEL: $MODEL
   python src/evaluation.py \
    --dataset $DATASET \
    --model $MODEL \
    --perturbation "$PERTURBATION" \
    --task t2i
done


MODEL=groupvit
declare -a PERTURBATIONS=(
    "extra_char"
    "probability_based_letter_change"
    )
for PERTURBATION in "${PERTURBATIONS[@]}"
do
   echo MODEL: $MODEL
   python src/evaluation.py \
    --dataset $DATASET \
    --model $MODEL \
    --perturbation "$PERTURBATION" \
    --task t2i
done
