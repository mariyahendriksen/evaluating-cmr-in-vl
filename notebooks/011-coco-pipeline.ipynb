{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from munch import Munch\n",
    "\n",
    "PROJECT_PATH = '/Users/mhendriksen/Desktop/repositories/evaluating-cmr-in-mm/'\n",
    "CONFIG_PATH = '/Users/mhendriksen/Desktop/repositories/evaluating-cmr-in-mm/config/development_local_coco.yaml'\n",
    "\n",
    "sys.path.append(PROJECT_PATH)\n",
    "\n",
    "with open(CONFIG_PATH, 'rb') as f:\n",
    "    config = Munch.fromYAML(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from munch import Munch\n",
    "\n",
    "PROJECT_PATH = '/Users/mhendriksen/Desktop/repositories/evaluating-cmr-in-mm/'\n",
    "CONFIG_PATH = '/Users/mhendriksen/Desktop/repositories/evaluating-cmr-in-mm/config/development_local_coco.yaml'\n",
    "\n",
    "sys.path.append(PROJECT_PATH)\n",
    "\n",
    "with open(CONFIG_PATH, 'rb') as f:\n",
    "    config = Munch.fromYAML(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded annotations from  /Users/mhendriksen/Desktop/repositories/datasets/coco/annotations/dataset_coco.json\n"
     ]
    }
   ],
   "source": [
    "from src.data.dataset import Dataset\n",
    "from src.utils.dataset_preprocessing import load_json_annotations\n",
    "\n",
    "json_file = load_json_annotations(config=config)\n",
    "\n",
    "coco_test_split = Dataset(\n",
    "    config=config,\n",
    "    split='test',\n",
    "    json_file=json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mhendriksen/Desktop/repositories/evaluating-cmr-in-mm/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "from PIL import Image\n",
    "import glob\n",
    "import torch\n",
    "import pickle\n",
    "import zipfile\n",
    "from IPython.display import display\n",
    "from IPython.display import Image as IPImage\n",
    "import os\n",
    "from tqdm.autonotebook import tqdm\n",
    "from munch import Munch\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "from src.models.encoders.clip import CLIP\n",
    "\n",
    "# load the model\n",
    "model = CLIP(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image embeddigns are already precomputed\n",
      "Loaded precomputed filenames and embeddings from  /Users/mhendriksen/Desktop/repositories/datasets/coco/coco-img-embeddings.pkl\n"
     ]
    }
   ],
   "source": [
    "# load precomputed image embeddings\n",
    "img_filenames, img_emb = model.compute_image_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved files to  /Users/mhendriksen/Desktop/repositories/datasets/coco/coco-img-embeddings.pkl\n"
     ]
    }
   ],
   "source": [
    "from src.utils.dataset_preprocessing import get_precomputed_embeddings_path, dump_filenames_embs_to_pkl\n",
    "\n",
    "img_emb_filename = get_precomputed_embeddings_path(config=config, dtype='img')\n",
    "image_data_precomputed = (img_filenames, img_emb)\n",
    "\n",
    "\n",
    "dump_filenames_embs_to_pkl(emb_file_path=img_emb_filename, data=image_data_precomputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing caption embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 196/196 [01:03<00:00,  3.06it/s]\n"
     ]
    }
   ],
   "source": [
    "capt_ids, capts, capt_embs = model.compute_caption_embeddings(ds_split=coco_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved files to  /Users/mhendriksen/Desktop/repositories/datasets/coco/coco-capt-embeddings.pkl\n"
     ]
    }
   ],
   "source": [
    "from src.utils.dataset_preprocessing import get_precomputed_embeddings_path, dump_filenames_embs_to_pkl, load_filenames_embs_from_pkl\n",
    "\n",
    "capt_emb_filename = get_precomputed_embeddings_path(config=config, dtype='capt')\n",
    "caption_data_precomputed = (capt_ids, capts, capt_embs)\n",
    "\n",
    "dump_filenames_embs_to_pkl(emb_file_path=capt_emb_filename, data=caption_data_precomputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to image evaluation...\n",
      "Progress: 100/25010\n",
      "Progress: 200/25010\n",
      "Progress: 300/25010\n",
      "Progress: 400/25010\n",
      "Progress: 500/25010\n",
      "Progress: 600/25010\n",
      "Progress: 700/25010\n",
      "Progress: 800/25010\n",
      "Progress: 900/25010\n",
      "Progress: 1000/25010\n",
      "Progress: 1100/25010\n",
      "Progress: 1200/25010\n",
      "Progress: 1300/25010\n",
      "Progress: 1400/25010\n",
      "Progress: 1500/25010\n",
      "Progress: 1600/25010\n",
      "Progress: 1700/25010\n",
      "Progress: 1800/25010\n",
      "Progress: 1900/25010\n",
      "Progress: 2000/25010\n",
      "Progress: 2100/25010\n",
      "Progress: 2200/25010\n",
      "Progress: 2300/25010\n",
      "Progress: 2400/25010\n",
      "Progress: 2500/25010\n",
      "Progress: 2600/25010\n",
      "Progress: 2700/25010\n",
      "Progress: 2800/25010\n",
      "Progress: 2900/25010\n",
      "Progress: 3000/25010\n",
      "Progress: 3100/25010\n",
      "Progress: 3200/25010\n",
      "Progress: 3300/25010\n",
      "Progress: 3400/25010\n",
      "Progress: 3500/25010\n",
      "Progress: 3600/25010\n",
      "Progress: 3700/25010\n",
      "Progress: 3800/25010\n",
      "Progress: 3900/25010\n",
      "Progress: 4000/25010\n",
      "Progress: 4100/25010\n",
      "Progress: 4200/25010\n",
      "Progress: 4300/25010\n",
      "Progress: 4400/25010\n",
      "Progress: 4500/25010\n",
      "Progress: 4600/25010\n",
      "Progress: 4700/25010\n",
      "Progress: 4800/25010\n",
      "Progress: 4900/25010\n",
      "Progress: 5000/25010\n",
      "Progress: 5100/25010\n",
      "Progress: 5200/25010\n",
      "Progress: 5300/25010\n",
      "Progress: 5400/25010\n",
      "Progress: 5500/25010\n",
      "Progress: 5600/25010\n",
      "Progress: 5700/25010\n",
      "Progress: 5800/25010\n",
      "Progress: 5900/25010\n",
      "Progress: 6000/25010\n",
      "Progress: 6100/25010\n",
      "Progress: 6200/25010\n",
      "Progress: 6300/25010\n",
      "Progress: 6400/25010\n",
      "Progress: 6500/25010\n",
      "Progress: 6600/25010\n",
      "Progress: 6700/25010\n",
      "Progress: 6800/25010\n",
      "Progress: 6900/25010\n",
      "Progress: 7000/25010\n",
      "Progress: 7100/25010\n",
      "Progress: 7200/25010\n",
      "Progress: 7300/25010\n",
      "Progress: 7400/25010\n",
      "Progress: 7500/25010\n",
      "Progress: 7600/25010\n",
      "Progress: 7700/25010\n",
      "Progress: 7800/25010\n",
      "Progress: 7900/25010\n",
      "Progress: 8000/25010\n",
      "Progress: 8100/25010\n",
      "Progress: 8200/25010\n",
      "Progress: 8300/25010\n",
      "Progress: 8400/25010\n",
      "Progress: 8500/25010\n",
      "Progress: 8600/25010\n",
      "Progress: 8700/25010\n",
      "Progress: 8800/25010\n",
      "Progress: 8900/25010\n",
      "Progress: 9000/25010\n",
      "Progress: 9100/25010\n",
      "Progress: 9200/25010\n",
      "Progress: 9300/25010\n",
      "Progress: 9400/25010\n",
      "Progress: 9500/25010\n",
      "Progress: 9600/25010\n",
      "Progress: 9700/25010\n",
      "Progress: 9800/25010\n",
      "Progress: 9900/25010\n",
      "Progress: 10000/25010\n",
      "Progress: 10100/25010\n",
      "Progress: 10200/25010\n",
      "Progress: 10300/25010\n",
      "Progress: 10400/25010\n",
      "Progress: 10500/25010\n",
      "Progress: 10600/25010\n",
      "Progress: 10700/25010\n",
      "Progress: 10800/25010\n",
      "Progress: 10900/25010\n",
      "Progress: 11000/25010\n",
      "Progress: 11100/25010\n",
      "Progress: 11200/25010\n",
      "Progress: 11300/25010\n",
      "Progress: 11400/25010\n",
      "Progress: 11500/25010\n",
      "Progress: 11600/25010\n",
      "Progress: 11700/25010\n",
      "Progress: 11800/25010\n",
      "Progress: 11900/25010\n",
      "Progress: 12000/25010\n",
      "Progress: 12100/25010\n",
      "Progress: 12200/25010\n",
      "Progress: 12300/25010\n",
      "Progress: 12400/25010\n",
      "Progress: 12500/25010\n",
      "Progress: 12600/25010\n",
      "Progress: 12700/25010\n",
      "Progress: 12800/25010\n",
      "Progress: 12900/25010\n",
      "Progress: 13000/25010\n",
      "Progress: 13100/25010\n",
      "Progress: 13200/25010\n",
      "Progress: 13300/25010\n",
      "Progress: 13400/25010\n",
      "Progress: 13500/25010\n",
      "Progress: 13600/25010\n",
      "Progress: 13700/25010\n",
      "Progress: 13800/25010\n",
      "Progress: 13900/25010\n",
      "Progress: 14000/25010\n",
      "Progress: 14100/25010\n",
      "Progress: 14200/25010\n",
      "Progress: 14300/25010\n",
      "Progress: 14400/25010\n",
      "Progress: 14500/25010\n",
      "Progress: 14600/25010\n",
      "Progress: 14700/25010\n",
      "Progress: 14800/25010\n",
      "Progress: 14900/25010\n",
      "Progress: 15000/25010\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from src.retrieval.retriever import Retriever\n",
    "from src.metrics.recall_at_k import recall_at_k\n",
    "from src.models.relevance_estimators.clip_based import RelevanceEstimator\n",
    "from src.metrics.dcg import DCG\n",
    "\n",
    "rel_estimator = RelevanceEstimator(config=config, dataset=coco_test_split)\n",
    "retriever = Retriever(config=config, model=model)\n",
    "dcg = DCG(config=config, rel_estimator=rel_estimator)\n",
    "\n",
    "t2i_queries = []\n",
    "t2i_targets = []\n",
    "t2i_retrieved_documents = []\n",
    "t2i_scores = []\n",
    "t2i_recalls_at_1 = []\n",
    "t2i_recalls_at_5 = []\n",
    "t2i_recalls_at_10 = []\n",
    "t2i_dcgs = []\n",
    "\n",
    "print('Text to image evaluation...')\n",
    "for datapoint in coco_test_split:\n",
    "    # get textual query and target\n",
    "    query = datapoint[0]\n",
    "    target_filename = datapoint[4]\n",
    "\n",
    "    retrieved_documents, scores = retriever.retrieve_top_k(\n",
    "        query=query,\n",
    "        documents=img_emb,\n",
    "        documents_names=img_filenames,\n",
    "        k=10\n",
    "        )\n",
    "    \n",
    "    # metrics:\n",
    "    # compute recall at k\n",
    "    # t2i recall: there is only one correct item in the collection, i.e., total_in_collection=1\n",
    "    t2i_recall_at_1 = recall_at_k(target_filename=target_filename, retrieved_documents=retrieved_documents, k=1, total_in_collection=1)\n",
    "    t2i_recall_at_5 = recall_at_k(target_filename=target_filename, retrieved_documents=retrieved_documents, k=5, total_in_collection=1)\n",
    "    t2i_recall_at_10 = recall_at_k(target_filename=target_filename, retrieved_documents=retrieved_documents, k=10, total_in_collection=1)\n",
    "    # print('t2i: recalls at 1, 5, 10: ', t2i_recall_at_1, t2i_recall_at_5, t2i_recall_at_10)\n",
    "\n",
    "    t2i_dcg = dcg.compute_dcg(query=query, target_filename=target_filename, retrieved_documents=retrieved_documents)\n",
    "    # print('T2i_dcg: ', t2i_dcg)\n",
    "\n",
    "    t2i_queries.append(query)\n",
    "    t2i_targets.append(target_filename)\n",
    "    t2i_retrieved_documents.append(retrieved_documents)\n",
    "    t2i_scores.append(scores)\n",
    "    t2i_recalls_at_1.append(t2i_recall_at_1)\n",
    "    t2i_recalls_at_5.append(t2i_recall_at_5)\n",
    "    t2i_recalls_at_10.append(t2i_recall_at_10)\n",
    "    t2i_dcgs.append(t2i_dcg)\n",
    "\n",
    "    if datapoint[-1] > 0 and datapoint[-1] % 100 == 0:\n",
    "        print(f'Progress: {datapoint[-1]}/{len(coco_test_split)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\n",
    "        't2i_queries': t2i_queries,\n",
    "        't2i_targets': t2i_targets,\n",
    "        't2i_retrieved_documents': t2i_retrieved_documents,\n",
    "        't2i_scores': t2i_scores,\n",
    "        't2i_recalls_at_1': t2i_recalls_at_1,\n",
    "        't2i_recalls_at_5': t2i_recalls_at_5,\n",
    "        't2i_recalls_at_10': t2i_recalls_at_10,\n",
    "        't2i_dcgs': t2i_dcgs\n",
    "        }\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "t2i_results = pd.DataFrame(\n",
    "    data=data\n",
    ")\n",
    "\n",
    "print(t2i_results.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.dataset_preprocessing import save_results_dataframe\n",
    "\n",
    "save_results_dataframe(config=config, dataf=t2i_results, filename='coco-t2i-results')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
