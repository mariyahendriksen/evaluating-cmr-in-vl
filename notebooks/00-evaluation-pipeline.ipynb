{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"http_proxy\"] = \"http://devproxy.bloomberg.com:82\"\n",
    "os.environ[\"https_proxy\"] = \"http://devproxy.bloomberg.com:82\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from munch import Munch\n",
    "\n",
    "PROJECT_PATH = '/Users/mhendriksen/Desktop/repositories/evaluating-cmr-in-mm/'\n",
    "CONFIG_PATH = '/Users/mhendriksen/Desktop/repositories/evaluating-cmr-in-mm/config/development_local_f30k.yaml'\n",
    "\n",
    "sys.path.append(PROJECT_PATH)\n",
    "\n",
    "with open(CONFIG_PATH, 'rb') as f:\n",
    "    config = Munch.fromYAML(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded annotations from  /Users/mhendriksen/Desktop/repositories/datasets/f30k/annotations/dataset_flickr30k.json\n"
     ]
    }
   ],
   "source": [
    "from src.data.dataset import Dataset\n",
    "from src.utils.dataset_preprocessing import load_json_annotations\n",
    "\n",
    "json_file = load_json_annotations(config=config)\n",
    "\n",
    "f30k_test_split = Dataset(\n",
    "    config=config,\n",
    "    split='test',\n",
    "    json_file=json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'src.models.encoders.clip.CLIP'>\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "from PIL import Image\n",
    "import glob\n",
    "import torch\n",
    "import pickle\n",
    "import zipfile\n",
    "from IPython.display import display\n",
    "from IPython.display import Image as IPImage\n",
    "import os\n",
    "from tqdm.autonotebook import tqdm\n",
    "from munch import Munch\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "from src.models.encoders.clip import CLIP\n",
    "\n",
    "# load the model\n",
    "model = CLIP(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-to-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image embeddigns are already precomputed\n",
      "Loaded precomputed filenames and embeddings from  /Users/mhendriksen/Desktop/repositories/datasets/f30k/f30k-img-embeddings.pkl\n"
     ]
    }
   ],
   "source": [
    "# load precomputed image embeddings\n",
    "f30k_img_filenames, f30k_img_emb = model.compute_image_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to image evaluation...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m t2i_recall_at_10 \u001b[39m=\u001b[39m recall_at_k(target_filename\u001b[39m=\u001b[39mtarget_filename, retrieved_documents\u001b[39m=\u001b[39mretrieved_documents, k\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, total_in_collection\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[39m# print('t2i: recalls at 1, 5, 10: ', t2i_recall_at_1, t2i_recall_at_5, t2i_recall_at_10)\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m t2i_dcg \u001b[39m=\u001b[39m dcg\u001b[39m.\u001b[39;49mcompute_dcg(query\u001b[39m=\u001b[39;49mquery, target_filename\u001b[39m=\u001b[39;49mtarget_filename, retrieved_documents\u001b[39m=\u001b[39;49mretrieved_documents)\n\u001b[1;32m     41\u001b[0m \u001b[39m# print('T2i_dcg: ', t2i_dcg)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m t2i_queries\u001b[39m.\u001b[39mappend(query)\n",
      "File \u001b[0;32m~/Desktop/repositories/evaluating-cmr-in-mm/src/metrics/dcg.py:80\u001b[0m, in \u001b[0;36mDCG.compute_dcg\u001b[0;34m(self, query, target_filename, retrieved_documents, caption_ids)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_dcg\u001b[39m(\u001b[39mself\u001b[39m, query, target_filename, retrieved_documents, caption_ids\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[0;32m---> 80\u001b[0m     gains \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_gains(\n\u001b[1;32m     81\u001b[0m         query\u001b[39m=\u001b[39;49mquery,\n\u001b[1;32m     82\u001b[0m         target_filename\u001b[39m=\u001b[39;49mtarget_filename,\n\u001b[1;32m     83\u001b[0m         retrieved_documents\u001b[39m=\u001b[39;49mretrieved_documents,\n\u001b[1;32m     84\u001b[0m         caption_ids\u001b[39m=\u001b[39;49mcaption_ids\n\u001b[1;32m     85\u001b[0m         )\n\u001b[1;32m     86\u001b[0m     \u001b[39m# print('Gains: ', gains)\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     dcg_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgains_to_dcg(gains\u001b[39m=\u001b[39mgains)\n",
      "File \u001b[0;32m~/Desktop/repositories/evaluating-cmr-in-mm/src/metrics/dcg.py:41\u001b[0m, in \u001b[0;36mDCG.get_gains\u001b[0;34m(self, query, target_filename, retrieved_documents, caption_ids)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39melif\u001b[39;00m target_filename \u001b[39m!=\u001b[39m doc:\n\u001b[1;32m     38\u001b[0m     \u001b[39m# print('Target_filename != doc; computing cross-modal relevance score...')\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(query, \u001b[39mstr\u001b[39m):\n\u001b[1;32m     40\u001b[0m         \u001b[39m# print('Query is a string')\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m         gain \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrel_estimator\u001b[39m.\u001b[39;49mcompute_relevance_estimation_t2i(query\u001b[39m=\u001b[39;49mquery, document\u001b[39m=\u001b[39;49mdoc)\n\u001b[1;32m     42\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(query, PIL\u001b[39m.\u001b[39mImage\u001b[39m.\u001b[39mImage):\n\u001b[1;32m     43\u001b[0m     \u001b[39m#     print('Query is an image ')\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[39m#     print('Query: ', query)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[39m#     print('Document: ', doc)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     \u001b[39m#     print('capt id: ', caption_ids[idx])\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[39m#     print('I2T RELEVANCE ESTIMATION: ', inspect.getsource(self.rel_estimator.compute_relevance_estimation_i2t))\u001b[39;00m\n\u001b[1;32m     48\u001b[0m         gain \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrel_estimator\u001b[39m.\u001b[39mcompute_relevance_estimation_i2t(query\u001b[39m=\u001b[39mquery, document\u001b[39m=\u001b[39mdoc, caption_id\u001b[39m=\u001b[39mcaption_ids[idx])\n",
      "File \u001b[0;32m~/Desktop/repositories/evaluating-cmr-in-mm/src/models/relevance_estimators/clip_based.py:53\u001b[0m, in \u001b[0;36mRelevanceEstimator.compute_relevance_estimation_t2i\u001b[0;34m(self, query, document)\u001b[0m\n\u001b[1;32m     51\u001b[0m query \u001b[39m=\u001b[39m query[:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mmax_seq_length]\n\u001b[1;32m     52\u001b[0m query_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode(query)\n\u001b[0;32m---> 53\u001b[0m document_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencode(img)\n\u001b[1;32m     54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mround\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msim_func(query_emb, document_emb)\u001b[39m.\u001b[39mitem(), \u001b[39m4\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/repositories/evaluating-cmr-in-mm/src/models/relevance_estimators/clip_based.py:37\u001b[0m, in \u001b[0;36mRelevanceEstimator.encode\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m---> 37\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackbone\u001b[39m.\u001b[39;49mencode(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/repositories/evaluating-cmr-in-mm/.venv/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:161\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39mfor\u001b[39;00m start_index \u001b[39min\u001b[39;00m trange(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(sentences), batch_size, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBatches\u001b[39m\u001b[39m\"\u001b[39m, disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m show_progress_bar):\n\u001b[1;32m    160\u001b[0m     sentences_batch \u001b[39m=\u001b[39m sentences_sorted[start_index:start_index\u001b[39m+\u001b[39mbatch_size]\n\u001b[0;32m--> 161\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenize(sentences_batch)\n\u001b[1;32m    162\u001b[0m     features \u001b[39m=\u001b[39m batch_to_device(features, device)\n\u001b[1;32m    164\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/Desktop/repositories/evaluating-cmr-in-mm/.venv/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:319\u001b[0m, in \u001b[0;36mSentenceTransformer.tokenize\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtokenize\u001b[39m(\u001b[39mself\u001b[39m, texts: Union[List[\u001b[39mstr\u001b[39m], List[Dict], List[Tuple[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]]]):\n\u001b[1;32m    316\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39m    Tokenizes the texts\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_first_module()\u001b[39m.\u001b[39;49mtokenize(texts)\n",
      "File \u001b[0;32m~/Desktop/repositories/evaluating-cmr-in-mm/.venv/lib/python3.9/site-packages/sentence_transformers/models/CLIPModel.py:71\u001b[0m, in \u001b[0;36mCLIPModel.tokenize\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(images) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     69\u001b[0m     images \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocessor(text\u001b[39m=\u001b[39;49mtexts_values, images\u001b[39m=\u001b[39;49mimages, return_tensors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m\"\u001b[39;49m, padding\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     72\u001b[0m inputs[\u001b[39m'\u001b[39m\u001b[39mimage_text_info\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m image_text_info\n\u001b[1;32m     73\u001b[0m \u001b[39mreturn\u001b[39;00m inputs\n",
      "File \u001b[0;32m~/Desktop/repositories/evaluating-cmr-in-mm/.venv/lib/python3.9/site-packages/transformers/models/clip/processing_clip.py:103\u001b[0m, in \u001b[0;36mCLIPProcessor.__call__\u001b[0;34m(self, text, images, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     encoding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer(text, return_tensors\u001b[39m=\u001b[39mreturn_tensors, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    102\u001b[0m \u001b[39mif\u001b[39;00m images \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m     image_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimage_processor(images, return_tensors\u001b[39m=\u001b[39;49mreturn_tensors, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m text \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m images \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     encoding[\u001b[39m\"\u001b[39m\u001b[39mpixel_values\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m image_features\u001b[39m.\u001b[39mpixel_values\n",
      "File \u001b[0;32m~/Desktop/repositories/evaluating-cmr-in-mm/.venv/lib/python3.9/site-packages/transformers/image_processing_utils.py:494\u001b[0m, in \u001b[0;36mBaseImageProcessor.__call__\u001b[0;34m(self, images, **kwargs)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, images, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BatchFeature:\n\u001b[1;32m    493\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Preprocess an image or a batch of images.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 494\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocess(images, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/repositories/evaluating-cmr-in-mm/.venv/lib/python3.9/site-packages/transformers/models/clip/image_processing_clip.py:295\u001b[0m, in \u001b[0;36mCLIPImageProcessor.preprocess\u001b[0;34m(self, images, do_resize, size, resample, do_center_crop, crop_size, do_rescale, rescale_factor, do_normalize, image_mean, image_std, do_convert_rgb, return_tensors, data_format, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m image_std \u001b[39m=\u001b[39m image_std \u001b[39mif\u001b[39;00m image_std \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_std\n\u001b[1;32m    293\u001b[0m do_convert_rgb \u001b[39m=\u001b[39m do_convert_rgb \u001b[39mif\u001b[39;00m do_convert_rgb \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_convert_rgb\n\u001b[0;32m--> 295\u001b[0m images \u001b[39m=\u001b[39m make_list_of_images(images)\n\u001b[1;32m    297\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m valid_images(images):\n\u001b[1;32m    298\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    299\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mInvalid image type. Must be of type PIL.Image.Image, numpy.ndarray, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtorch.Tensor, tf.Tensor or jax.ndarray.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    301\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/repositories/evaluating-cmr-in-mm/.venv/lib/python3.9/site-packages/transformers/image_utils.py:111\u001b[0m, in \u001b[0;36mmake_list_of_images\u001b[0;34m(images, expected_ndims)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_list_of_images\u001b[39m(images, expected_ndims: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[ImageInput]:\n\u001b[1;32m    100\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39m    Ensure that the input is a list of images. If the input is a single image, it is converted to a list of length 1.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[39m    If the input is a batch of images, it is converted to a list of images.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39m            dimensions, an error is raised.\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m     \u001b[39mif\u001b[39;00m is_batched(images):\n\u001b[1;32m    112\u001b[0m         \u001b[39mreturn\u001b[39;00m images\n\u001b[1;32m    114\u001b[0m     \u001b[39m# Either the input is a single image, in which case we create a list of length 1\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/repositories/evaluating-cmr-in-mm/.venv/lib/python3.9/site-packages/transformers/image_utils.py:95\u001b[0m, in \u001b[0;36mis_batched\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_batched\u001b[39m(img):\n\u001b[1;32m     94\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(img, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m---> 95\u001b[0m         \u001b[39mreturn\u001b[39;00m is_valid_image(img[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/repositories/evaluating-cmr-in-mm/.venv/lib/python3.9/site-packages/transformers/image_utils.py:73\u001b[0m, in \u001b[0;36mis_valid_image\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_valid_image\u001b[39m(img):\n\u001b[1;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m---> 73\u001b[0m         (is_vision_available() \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(img, PIL\u001b[39m.\u001b[39mImage\u001b[39m.\u001b[39mImage))\n\u001b[1;32m     74\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(img, np\u001b[39m.\u001b[39mndarray)\n\u001b[1;32m     75\u001b[0m         \u001b[39mor\u001b[39;00m is_torch_tensor(img)\n\u001b[1;32m     76\u001b[0m         \u001b[39mor\u001b[39;00m is_tf_tensor(img)\n\u001b[1;32m     77\u001b[0m         \u001b[39mor\u001b[39;00m is_jax_tensor(img)\n\u001b[1;32m     78\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/repositories/evaluating-cmr-in-mm/.venv/lib/python3.9/site-packages/transformers/utils/import_utils.py:547\u001b[0m, in \u001b[0;36mis_vision_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[39mif\u001b[39;00m _pil_available:\n\u001b[1;32m    546\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 547\u001b[0m         package_version \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mmetadata\u001b[39m.\u001b[39;49mversion(\u001b[39m\"\u001b[39;49m\u001b[39mPillow\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    548\u001b[0m     \u001b[39mexcept\u001b[39;00m importlib\u001b[39m.\u001b[39mmetadata\u001b[39m.\u001b[39mPackageNotFoundError:\n\u001b[1;32m    549\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/importlib/metadata.py:551\u001b[0m, in \u001b[0;36mversion\u001b[0;34m(distribution_name)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mversion\u001b[39m(distribution_name):\n\u001b[1;32m    545\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get the version string for the named package.\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \n\u001b[1;32m    547\u001b[0m \u001b[39m    :param distribution_name: The name of the distribution package to query.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[39m    :return: The version string for the package as defined in the package's\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[39m        \"Version\" metadata key.\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 551\u001b[0m     \u001b[39mreturn\u001b[39;00m distribution(distribution_name)\u001b[39m.\u001b[39;49mversion\n",
      "File \u001b[0;32m~/Desktop/repositories/evaluating-cmr-in-mm/.venv/lib/python3.9/site-packages/importlib_metadata/__init__.py:478\u001b[0m, in \u001b[0;36mDistribution.version\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    476\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mversion\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    477\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the 'Version' metadata for the distribution package.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 478\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetadata[\u001b[39m'\u001b[39m\u001b[39mVersion\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/repositories/evaluating-cmr-in-mm/.venv/lib/python3.9/site-packages/importlib_metadata/__init__.py:463\u001b[0m, in \u001b[0;36mDistribution.metadata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m opt_text \u001b[39m=\u001b[39m (\n\u001b[1;32m    455\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_text(\u001b[39m'\u001b[39m\u001b[39mMETADATA\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    456\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_text(\u001b[39m'\u001b[39m\u001b[39mPKG-INFO\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_text(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    461\u001b[0m )\n\u001b[1;32m    462\u001b[0m text \u001b[39m=\u001b[39m cast(\u001b[39mstr\u001b[39m, opt_text)\n\u001b[0;32m--> 463\u001b[0m \u001b[39mreturn\u001b[39;00m _adapters\u001b[39m.\u001b[39mMessage(email\u001b[39m.\u001b[39;49mmessage_from_string(text))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/email/__init__.py:38\u001b[0m, in \u001b[0;36mmessage_from_string\u001b[0;34m(s, *args, **kws)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Parse a string into a Message object model.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \n\u001b[1;32m     35\u001b[0m \u001b[39mOptional _class and strict are passed to the Parser constructor.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39memail\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparser\u001b[39;00m \u001b[39mimport\u001b[39;00m Parser\n\u001b[0;32m---> 38\u001b[0m \u001b[39mreturn\u001b[39;00m Parser(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkws)\u001b[39m.\u001b[39;49mparsestr(s)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/email/parser.py:67\u001b[0m, in \u001b[0;36mParser.parsestr\u001b[0;34m(self, text, headersonly)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparsestr\u001b[39m(\u001b[39mself\u001b[39m, text, headersonly\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     60\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create a message structure from a string.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[39m    Returns the root of the message structure.  Optional headersonly is a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39m    the file.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse(StringIO(text), headersonly\u001b[39m=\u001b[39;49mheadersonly)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/email/parser.py:56\u001b[0m, in \u001b[0;36mParser.parse\u001b[0;34m(self, fp, headersonly)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data:\n\u001b[1;32m     55\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     feedparser\u001b[39m.\u001b[39;49mfeed(data)\n\u001b[1;32m     57\u001b[0m \u001b[39mreturn\u001b[39;00m feedparser\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/email/feedparser.py:176\u001b[0m, in \u001b[0;36mFeedParser.feed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Push more data into the parser.\"\"\"\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input\u001b[39m.\u001b[39mpush(data)\n\u001b[0;32m--> 176\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_parse()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/email/feedparser.py:180\u001b[0m, in \u001b[0;36mFeedParser._call_parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_parse\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    179\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 180\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse()\n\u001b[1;32m    181\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/email/feedparser.py:228\u001b[0m, in \u001b[0;36mFeedParser._parsegen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[39myield\u001b[39;00m NeedMoreData\n\u001b[1;32m    227\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m headerRE\u001b[39m.\u001b[39;49mmatch(line):\n\u001b[1;32m    229\u001b[0m     \u001b[39m# If we saw the RFC defined header/body separator\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[39m# (i.e. newline), just throw it away. Otherwise the line is\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     \u001b[39m# part of the body so push it back.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m NLCRE\u001b[39m.\u001b[39mmatch(line):\n\u001b[1;32m    233\u001b[0m         defect \u001b[39m=\u001b[39m errors\u001b[39m.\u001b[39mMissingHeaderBodySeparatorDefect()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.retrieval.retriever import Retriever\n",
    "from src.metrics.recall_at_k import recall_at_k\n",
    "from src.models.relevance_estimators.clip_based import RelevanceEstimator\n",
    "from src.metrics.dcg import DCG\n",
    "\n",
    "rel_estimator = RelevanceEstimator(config=config, dataset=f30k_test_split)\n",
    "retriever = Retriever(config=config, model=model)\n",
    "dcg = DCG(config=config, rel_estimator=rel_estimator)\n",
    "\n",
    "t2i_queries = []\n",
    "t2i_targets = []\n",
    "t2i_retrieved_documents = []\n",
    "t2i_scores = []\n",
    "t2i_recalls_at_1 = []\n",
    "t2i_recalls_at_5 = []\n",
    "t2i_recalls_at_10 = []\n",
    "t2i_dcgs = []\n",
    "\n",
    "print('Text to image evaluation...')\n",
    "for datapoint in f30k_test_split:\n",
    "    # get textual query and target\n",
    "    query = datapoint[0]\n",
    "    target_filename = datapoint[4]\n",
    "\n",
    "    retrieved_documents, scores = retriever.retrieve_top_k(\n",
    "        query=query,\n",
    "        documents=f30k_img_emb,\n",
    "        documents_names=f30k_img_filenames,\n",
    "        k=10\n",
    "        )\n",
    "    \n",
    "    # metrics:\n",
    "    # compute recall at k\n",
    "    # t2i recall: there is only one correct item in the collection, i.e., total_in_collection=1\n",
    "    t2i_recall_at_1 = recall_at_k(target_filename=target_filename, retrieved_documents=retrieved_documents, k=1, total_in_collection=1)\n",
    "    t2i_recall_at_5 = recall_at_k(target_filename=target_filename, retrieved_documents=retrieved_documents, k=5, total_in_collection=1)\n",
    "    t2i_recall_at_10 = recall_at_k(target_filename=target_filename, retrieved_documents=retrieved_documents, k=10, total_in_collection=1)\n",
    "    # print('t2i: recalls at 1, 5, 10: ', t2i_recall_at_1, t2i_recall_at_5, t2i_recall_at_10)\n",
    "\n",
    "    t2i_dcg = dcg.compute_dcg(query=query, target_filename=target_filename, retrieved_documents=retrieved_documents)\n",
    "    # print('T2i_dcg: ', t2i_dcg)\n",
    "\n",
    "    t2i_queries.append(query)\n",
    "    t2i_targets.append(target_filename)\n",
    "    t2i_retrieved_documents.append(retrieved_documents)\n",
    "    t2i_scores.append(scores)\n",
    "    t2i_recalls_at_1.append(t2i_recall_at_1)\n",
    "    t2i_recalls_at_5.append(t2i_recall_at_5)\n",
    "    t2i_recalls_at_10.append(t2i_recall_at_10)\n",
    "    t2i_dcgs.append(t2i_dcg)\n",
    "\n",
    "    if datapoint[-1] > 0 and datapoint[-1] % 100 == 0:\n",
    "        print(f'Progress: {datapoint[-1]}/{len(f30k_test_split)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t2i_recalls_at_1</th>\n",
       "      <th>t2i_recalls_at_5</th>\n",
       "      <th>t2i_recalls_at_10</th>\n",
       "      <th>t2i_dcgs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.193000</td>\n",
       "      <td>0.397400</td>\n",
       "      <td>0.492200</td>\n",
       "      <td>1.702666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.394692</td>\n",
       "      <td>0.489409</td>\n",
       "      <td>0.499989</td>\n",
       "      <td>0.266153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.062100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.486975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.616800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.901150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.317900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       t2i_recalls_at_1  t2i_recalls_at_5  t2i_recalls_at_10     t2i_dcgs\n",
       "count       5000.000000       5000.000000        5000.000000  5000.000000\n",
       "mean           0.193000          0.397400           0.492200     1.702666\n",
       "std            0.394692          0.489409           0.499989     0.266153\n",
       "min            0.000000          0.000000           0.000000     1.062100\n",
       "25%            0.000000          0.000000           0.000000     1.486975\n",
       "50%            0.000000          0.000000           0.000000     1.616800\n",
       "75%            0.000000          1.000000           1.000000     1.901150\n",
       "max            1.000000          1.000000           1.000000     2.317900"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data={\n",
    "        't2i_queries': t2i_queries,\n",
    "        't2i_targets': t2i_targets,\n",
    "        't2i_retrieved_documents': t2i_retrieved_documents,\n",
    "        't2i_scores': t2i_scores,\n",
    "        't2i_recalls_at_1': t2i_recalls_at_1,\n",
    "        't2i_recalls_at_5': t2i_recalls_at_5,\n",
    "        't2i_recalls_at_10': t2i_recalls_at_10,\n",
    "        't2i_dcgs': t2i_dcgs\n",
    "        }\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "t2i_results = pd.DataFrame(\n",
    "    data=data\n",
    ")\n",
    "\n",
    "t2i_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataframe to  /Users/mhendriksen/Desktop/repositories/evaluating-cmr-in-mm/results/f30k-t2i-results.pkl\n"
     ]
    }
   ],
   "source": [
    "from src.utils.dataset_preprocessing import save_results_dataframe\n",
    "\n",
    "save_results_dataframe(config=config, dataf=t2i_results, filename='f30k-t2i-results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f30k_img_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image-to-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption embeddigns are already precomputed\n",
      "Loaded precomputed filenames and embeddings from  /Users/mhendriksen/Desktop/repositories/datasets/f30k/f30k-capt-embeddings.pkl\n"
     ]
    }
   ],
   "source": [
    "f30k_capt_ids, f30k_capts, f30k_capt_embs = model.compute_caption_embeddings(ds_split=f30k_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f30k_capt_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The man with pierced ears is wearing glasses and an orange hat.'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f30k_capts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f30k_capt_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved files to  /Users/mhendriksen/Desktop/repositories/datasets/f30k/f30k-capt-embeddings.pkl\n"
     ]
    }
   ],
   "source": [
    "from src.utils.dataset_preprocessing import get_precomputed_embeddings_path, dump_filenames_embs_to_pkl\n",
    "\n",
    "emb_path = get_precomputed_embeddings_path(config=config, dtype='capt')\n",
    "\n",
    "dump_filenames_embs_to_pkl(emb_file_path=emb_path,\n",
    "                           data=(f30k_capt_ids, f30k_capts, f30k_capt_embs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9242"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.dataset_preprocessing import get_precomputed_embeddings_path, dump_filenames_embs_to_pkl, load_filenames_embs_from_pkl\n",
    "\n",
    "capt_emb_filename = get_precomputed_embeddings_path(config=config, dtype='capt')\n",
    "caption_data_precomputed = (f30k_capt_ids, f30k_capts, f30k_capt_embs)\n",
    "\n",
    "if not os.path.exists(img_emb_filename):\n",
    "    dump_filenames_embs_to_pkl(emb_file_path=img_emb_filename, data=caption_data_precomputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25010, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "path = '/Users/mhendriksen/Desktop/repositories/evaluating-cmr-in-mm/results/coco-i2t-results.pkl'\n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image to text evaluation...\n",
      "Progress: 100/5000\n",
      "Progress: 200/5000\n",
      "Progress: 300/5000\n",
      "Progress: 400/5000\n",
      "Progress: 500/5000\n",
      "Progress: 600/5000\n",
      "Progress: 700/5000\n",
      "Progress: 800/5000\n",
      "Progress: 900/5000\n",
      "Progress: 1000/5000\n",
      "Progress: 1100/5000\n",
      "Progress: 1200/5000\n",
      "Progress: 1300/5000\n",
      "Progress: 1400/5000\n",
      "Progress: 1500/5000\n",
      "Progress: 1600/5000\n",
      "Progress: 1700/5000\n",
      "Progress: 1800/5000\n",
      "Progress: 1900/5000\n",
      "Progress: 2000/5000\n",
      "Progress: 2100/5000\n",
      "Progress: 2200/5000\n",
      "Progress: 2300/5000\n",
      "Progress: 2400/5000\n",
      "Progress: 2500/5000\n",
      "Progress: 2600/5000\n",
      "Progress: 2700/5000\n",
      "Progress: 2800/5000\n",
      "Progress: 2900/5000\n",
      "Progress: 3000/5000\n",
      "Progress: 3100/5000\n",
      "Progress: 3200/5000\n",
      "Progress: 3300/5000\n",
      "Progress: 3400/5000\n",
      "Progress: 3500/5000\n",
      "Progress: 3600/5000\n",
      "Progress: 3700/5000\n",
      "Progress: 3800/5000\n",
      "Progress: 3900/5000\n",
      "Progress: 4000/5000\n",
      "Progress: 4100/5000\n",
      "Progress: 4200/5000\n",
      "Progress: 4300/5000\n",
      "Progress: 4400/5000\n",
      "Progress: 4500/5000\n",
      "Progress: 4600/5000\n",
      "Progress: 4700/5000\n",
      "Progress: 4800/5000\n",
      "Progress: 4900/5000\n"
     ]
    }
   ],
   "source": [
    "from src.retrieval.retriever import Retriever\n",
    "from src.metrics.recall_at_k import recall_at_k\n",
    "from src.metrics.dcg import DCG\n",
    "\n",
    "retriever = Retriever(config=config, model=model)\n",
    "dcg = DCG(config=config, rel_estimator=rel_estimator)\n",
    "\n",
    "i2t_queries = []\n",
    "i2t_targets = []\n",
    "i2t_retrieved_documents = []\n",
    "i2t_scores = []\n",
    "i2t_recalls_at_1 = []\n",
    "i2t_recalls_at_5 = []\n",
    "i2t_recalls_at_10 = []\n",
    "i2t_dcgs = []\n",
    "\n",
    "print('Image to text evaluation...')\n",
    "for datapoint in f30k_test_split:\n",
    "    # get textual query and target\n",
    "    query = datapoint[1]\n",
    "    target_filename = datapoint[3]\n",
    "\n",
    "\n",
    "    retrieved_caption_ids, scores = retriever.retrieve_top_k(\n",
    "        query=query,\n",
    "        documents=f30k_capt_embs,\n",
    "        documents_names=f30k_capt_ids,\n",
    "        k=10\n",
    "        )\n",
    "\n",
    "    associated_img_ids = [f30k_test_split.captions[capt_id]['imgid'] for capt_id in retrieved_caption_ids]\n",
    "    # print('retrieved_caption_ids: ', retrieved_caption_ids)\n",
    "    # print('associated_img_ids: ', associated_img_ids)\n",
    "    \n",
    "    # metrics:\n",
    "    # compute recall at k\n",
    "    # i2t recall: there is only one correct item in the collection, i.e., total_in_collection=1\n",
    "    i2t_recall_at_1 = recall_at_k(target_filename=target_filename, retrieved_documents=associated_img_ids, k=1, total_in_collection=5)\n",
    "    i2t_recall_at_5 = recall_at_k(target_filename=target_filename, retrieved_documents=associated_img_ids, k=5, total_in_collection=5)\n",
    "    i2t_recall_at_10 = recall_at_k(target_filename=target_filename, retrieved_documents=associated_img_ids, k=10, total_in_collection=5)\n",
    "    # print('i2t: recalls at 1, 5, 10: ', i2t_recall_at_1, i2t_recall_at_5, i2t_recall_at_10)\n",
    "\n",
    "    i2t_dcg = dcg.compute_dcg(query=query, target_filename=target_filename, retrieved_documents=associated_img_ids, caption_ids=retrieved_caption_ids)\n",
    "    # print('i2t_dcg: ', i2t_dcg)\n",
    "\n",
    "    i2t_queries.append(query)\n",
    "    i2t_targets.append(target_filename)\n",
    "    i2t_retrieved_documents.append(retrieved_documents)\n",
    "    i2t_scores.append(scores)\n",
    "    i2t_recalls_at_1.append(i2t_recall_at_1)\n",
    "    i2t_recalls_at_5.append(i2t_recall_at_5)\n",
    "    i2t_recalls_at_10.append(i2t_recall_at_10)\n",
    "    i2t_dcgs.append(i2t_dcg)\n",
    "\n",
    "    if datapoint[-1] > 0 and datapoint[-1] % 100 == 0:\n",
    "        print(f'Progress: {datapoint[-1]}/{len(f30k_test_split)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i2t_queries</th>\n",
       "      <th>i2t_targets</th>\n",
       "      <th>i2t_retrieved_documents</th>\n",
       "      <th>i2t_scores</th>\n",
       "      <th>i2t_recalls_at_1</th>\n",
       "      <th>i2t_recalls_at_5</th>\n",
       "      <th>i2t_recalls_at_10</th>\n",
       "      <th>i2t_dcgs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>[2149968397.jpg, 90168112.jpg, 3457856049.jpg,...</td>\n",
       "      <td>[0.3575, 0.3318, 0.3113, 0.297, 0.2944, 0.2887...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>[2149968397.jpg, 90168112.jpg, 3457856049.jpg,...</td>\n",
       "      <td>[0.3575, 0.3318, 0.3113, 0.297, 0.2944, 0.2887...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>[2149968397.jpg, 90168112.jpg, 3457856049.jpg,...</td>\n",
       "      <td>[0.3575, 0.3318, 0.3113, 0.297, 0.2944, 0.2887...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>[2149968397.jpg, 90168112.jpg, 3457856049.jpg,...</td>\n",
       "      <td>[0.3575, 0.3318, 0.3113, 0.297, 0.2944, 0.2887...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>[2149968397.jpg, 90168112.jpg, 3457856049.jpg,...</td>\n",
       "      <td>[0.3575, 0.3318, 0.3113, 0.297, 0.2944, 0.2887...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>30943</td>\n",
       "      <td>30943</td>\n",
       "      <td>[2149968397.jpg, 90168112.jpg, 3457856049.jpg,...</td>\n",
       "      <td>[0.3198, 0.3172, 0.3064, 0.3049, 0.299, 0.2976...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.2817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>30943</td>\n",
       "      <td>30943</td>\n",
       "      <td>[2149968397.jpg, 90168112.jpg, 3457856049.jpg,...</td>\n",
       "      <td>[0.3198, 0.3172, 0.3064, 0.3049, 0.299, 0.2976...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.2817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>30943</td>\n",
       "      <td>30943</td>\n",
       "      <td>[2149968397.jpg, 90168112.jpg, 3457856049.jpg,...</td>\n",
       "      <td>[0.3198, 0.3172, 0.3064, 0.3049, 0.299, 0.2976...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.2817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>30943</td>\n",
       "      <td>30943</td>\n",
       "      <td>[2149968397.jpg, 90168112.jpg, 3457856049.jpg,...</td>\n",
       "      <td>[0.3198, 0.3172, 0.3064, 0.3049, 0.299, 0.2976...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.2817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>30943</td>\n",
       "      <td>30943</td>\n",
       "      <td>[2149968397.jpg, 90168112.jpg, 3457856049.jpg,...</td>\n",
       "      <td>[0.3198, 0.3172, 0.3064, 0.3049, 0.299, 0.2976...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.2817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      i2t_queries  i2t_targets  \\\n",
       "0              25           25   \n",
       "1              25           25   \n",
       "2              25           25   \n",
       "3              25           25   \n",
       "4              25           25   \n",
       "...           ...          ...   \n",
       "4995        30943        30943   \n",
       "4996        30943        30943   \n",
       "4997        30943        30943   \n",
       "4998        30943        30943   \n",
       "4999        30943        30943   \n",
       "\n",
       "                                i2t_retrieved_documents  \\\n",
       "0     [2149968397.jpg, 90168112.jpg, 3457856049.jpg,...   \n",
       "1     [2149968397.jpg, 90168112.jpg, 3457856049.jpg,...   \n",
       "2     [2149968397.jpg, 90168112.jpg, 3457856049.jpg,...   \n",
       "3     [2149968397.jpg, 90168112.jpg, 3457856049.jpg,...   \n",
       "4     [2149968397.jpg, 90168112.jpg, 3457856049.jpg,...   \n",
       "...                                                 ...   \n",
       "4995  [2149968397.jpg, 90168112.jpg, 3457856049.jpg,...   \n",
       "4996  [2149968397.jpg, 90168112.jpg, 3457856049.jpg,...   \n",
       "4997  [2149968397.jpg, 90168112.jpg, 3457856049.jpg,...   \n",
       "4998  [2149968397.jpg, 90168112.jpg, 3457856049.jpg,...   \n",
       "4999  [2149968397.jpg, 90168112.jpg, 3457856049.jpg,...   \n",
       "\n",
       "                                             i2t_scores  i2t_recalls_at_1  \\\n",
       "0     [0.3575, 0.3318, 0.3113, 0.297, 0.2944, 0.2887...               1.0   \n",
       "1     [0.3575, 0.3318, 0.3113, 0.297, 0.2944, 0.2887...               1.0   \n",
       "2     [0.3575, 0.3318, 0.3113, 0.297, 0.2944, 0.2887...               1.0   \n",
       "3     [0.3575, 0.3318, 0.3113, 0.297, 0.2944, 0.2887...               1.0   \n",
       "4     [0.3575, 0.3318, 0.3113, 0.297, 0.2944, 0.2887...               1.0   \n",
       "...                                                 ...               ...   \n",
       "4995  [0.3198, 0.3172, 0.3064, 0.3049, 0.299, 0.2976...               1.0   \n",
       "4996  [0.3198, 0.3172, 0.3064, 0.3049, 0.299, 0.2976...               1.0   \n",
       "4997  [0.3198, 0.3172, 0.3064, 0.3049, 0.299, 0.2976...               1.0   \n",
       "4998  [0.3198, 0.3172, 0.3064, 0.3049, 0.299, 0.2976...               1.0   \n",
       "4999  [0.3198, 0.3172, 0.3064, 0.3049, 0.299, 0.2976...               1.0   \n",
       "\n",
       "      i2t_recalls_at_5  i2t_recalls_at_10  i2t_dcgs  \n",
       "0                  1.0                1.0    1.3534  \n",
       "1                  1.0                1.0    1.3534  \n",
       "2                  1.0                1.0    1.3534  \n",
       "3                  1.0                1.0    1.3534  \n",
       "4                  1.0                1.0    1.3534  \n",
       "...                ...                ...       ...  \n",
       "4995               0.6                0.6   -0.2817  \n",
       "4996               0.6                0.6   -0.2817  \n",
       "4997               0.6                0.6   -0.2817  \n",
       "4998               0.6                0.6   -0.2817  \n",
       "4999               0.6                0.6   -0.2817  \n",
       "\n",
       "[5000 rows x 8 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data={\n",
    "        'i2t_queries': i2t_targets,\n",
    "        'i2t_targets': i2t_targets,\n",
    "        'i2t_retrieved_documents': i2t_retrieved_documents,\n",
    "        'i2t_scores': i2t_scores,\n",
    "        'i2t_recalls_at_1': i2t_recalls_at_1,\n",
    "        'i2t_recalls_at_5': i2t_recalls_at_5,\n",
    "        'i2t_recalls_at_10': i2t_recalls_at_10,\n",
    "        'i2t_dcgs': i2t_dcgs\n",
    "        }\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "i2t_results = pd.DataFrame(\n",
    "    data=data\n",
    ")\n",
    "\n",
    "i2t_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(t2i_queries))\n",
    "print(len(t2i_targets))\n",
    "print(len(t2i_retrieved_documents))\n",
    "print(len(t2i_scores))\n",
    "print(len(t2i_recalls_at_1))\n",
    "print(len(t2i_recalls_at_5))\n",
    "print(len(t2i_recalls_at_10))\n",
    "print(len(t2i_dcgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "endpoint_url='http://s3.dev.obdc.bcs.bloomberg.com'\n",
    "aws_access_key_id='J8I524PGEG4KVPV14HM7'\n",
    "aws_secret_access_key='jhfJZBCQR6GHUq4VlImx8gOeAW3BA5wnSL08lqBJ'\n",
    "\n",
    "client = boto3.client(\n",
    "      's3',\n",
    "      aws_access_key_id = aws_access_key_id,\n",
    "      aws_secret_access_key = aws_secret_access_key,\n",
    "      endpoint_url = endpoint_url\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upload_file('./test.txt', 'mariya', 'coco/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "subset = []\n",
    "prefix = './test'\n",
    "for el in client.list_objects(Bucket='mariya')['Contents']:\n",
    "    # print(el['Key'])\n",
    "    # print(type(el['Key']))\n",
    "    if el['Key'].startswith(prefix):\n",
    "        subset.append(el)\n",
    "        # client.download_file('mariya', el['Key'], el['Key'])\n",
    "subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/mhendriksen/Desktop/repositories/evaluating-cmr-in-mm/results/coco-t2i-results.pkl'\n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    coco_t2i_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.Image.Image"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PIL\n",
    "\n",
    "PIL.Image.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1722139382.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[72], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    which python\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "which python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
